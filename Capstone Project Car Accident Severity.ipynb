{
    "cells": [
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Car Accident Severity Resulting in Fatalities #\n\n## Introduction ##\n'Since March 2020 the corona-virus pandemic a _shelter-in-place_ order has minimized vehicles on thr roadways.  Instead of the minimal vehicles on the roadways, providing a safer  enviroment and insurance claim activity [cost], the opposite has occured.  Between the National Highway Safety Admininstration (NHTSA) and Insurance Service Office (ISO), car accident severity is rising at an alarming pace.  How can this be correct!  Basic logical deduction: _Less vehicle traffic produces less traffic accidents, especially server accidents._\n\nIn today's news, one health spokeman announced that the corona-virus pandemic's United States _shelter-in-place_ strategy could last until the end of 2021!  This is a study using Machine Learning alogrithms to __predict__ 07/2020 to 06/2021 fatalities based on a prior 12 months of data.'\n\n## Business Problem ##\n'Annually, insurance companies perform a _rate-making_ process to set premium rates, also known as _insurance pricing_. A rate is the price unit of insurance for each exposure unit. Vehicle coverage as property and casualty insurance, the exposure unit is typically equal to \\\\$100 of property value, and liability is measured in \\\\$1000 units. This study is focused on liability.'\n\n'Key _rate-making_ personnel are insurance underwriters and actuaries.'\n\n'The _rate-making_ process workflow is as follows:\n> 1. Identify the car accidents with fatalities data points\n> 2. Categorize data points: car fatalities, timing and volume\n> 3. Select Machine Learning Predictive Alogritm\n> 4. Perform Parameter Tuning and Averaging\n> 5. Create 2021 rates\n\n \n\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Data Section ##\n\n### Resources ###\n\n> __NHTSA: Early Estimates of Motoer Vehicle Fatalities, 2019__\n>> - Fatalities Quarterly data with percentage of change\n>> - 10-Regional counts and percentage of change<br>\n\n> __Injury Facts NSC: Traffic Volume/Averages__\n>> - Volume of Miles Driven\n>> - Number deaths\n>> - Number of Fatal Crashes<br>\n\n> __NSC January 2019 and June 2020__\n>> - Total U.S. Motor Vehicle Deaths\n>>>  - comparisons for 2020, 2019, 2018\n>>>  - percentage change\n>>>>   - 2019 to 2020\n>>>>   - 2018 to 2020\n\nUsing supervised learning to identify data patterns in creating __2021__ fatalities predictions based on above mentioned analysis."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Methodology ##\n\nMachine Learning Pipeline: (numbered in processing order)\n> 1. preprocessing data\n> 2. selection of feature(s)\n> 3. extraction of feature(s)\n> 4. train - test - split\n> 5. algorithm selection\n> 6. fit the models\n> 7. tunr the parameters\n> 8. _prediction_\n> 9. evaluation\n\n\n\n#### Source Data ####\n'To coincide with existing __Car Accident Fatality__ findings only NSC monthly numbers are analyzed.  Data is compiled in monthly Excel spreadsheets.  Consider the spreadsheets as source data.  The source data populate *accident* Pandas dataframe. Accident dataframe contents '\n\n#### Feature Extraction ####\nComparing data from 2009 versus 2020  \n> Identify trends and/or patterns\n> Vehicle Miles Traveled (VMT)\n> Fatality Rate per 100 million VMT\n\n#### Machine Learning Model ###\n'Supervised Learning algoritms will afford using the patterns in the traffic fatalities data to make predictions. Random Forests Algorithm afford prediction, analysis and results. \n\n__Justification:__\n> Prediction for *Probabilites, Categorical Outcomes and Continous Outcomes*\n> Analysis is *Simple to Use*\n> Results are *Highly Accurate*\n\n__Note for Model Tuning Parameters strategies:__\n> Adjusting all the parameters of the Decision Tree\n> Changing the Number of Trees\n> Number of variables to select at the split\n\n## Results ##\nUse current report analysis are benchmark and provide findings for consideration to *Rate-making* process. Fatalities have a strong influence of liability cost considerations and insurer exposture. \n\n## Discussion ##\n\n## Conclusion ##"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Report Analysis"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Preprocessing",
            "execution_count": 1,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### The Study ####\n>1. Prepare data (3 datasets featuring years, months, miles travelled and fatalities).\n>2. Applying a different algorithm to each dataset.\n>3. Tune algorithms to optimize the models.\n>4. Evaluate models based on their accuracy."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing",
            "execution_count": 33,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": false
            },
            "cell_type": "code",
            "source": "# Dataset 1: Fatalities Percentage Change Annually by Quarter  \n\ndf = pd.read_csv('Percentage_change.csv',delimiter=';')\ndf.head()",
            "execution_count": 34,
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>1Q</th>\n      <th>2Q</th>\n      <th>3Q</th>\n      <th>4Q</th>\n      <th>Annual</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2009</td>\n      <td>-10.7</td>\n      <td>-4.9</td>\n      <td>-8.5</td>\n      <td>-13.9</td>\n      <td>-9.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2010</td>\n      <td>-10.6</td>\n      <td>-5.0</td>\n      <td>1.3</td>\n      <td>3.0</td>\n      <td>-2.6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2011</td>\n      <td>-0.4</td>\n      <td>-3.5</td>\n      <td>-2.6</td>\n      <td>0.5</td>\n      <td>-1.6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2012</td>\n      <td>11.8</td>\n      <td>4.7</td>\n      <td>2.1</td>\n      <td>-0.7</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2013</td>\n      <td>-4.7</td>\n      <td>-4.7</td>\n      <td>-1.6</td>\n      <td>0.2</td>\n      <td>-2.6</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   Year    1Q   2Q   3Q    4Q  Annual\n0  2009 -10.7 -4.9 -8.5 -13.9    -9.5\n1  2010 -10.6 -5.0  1.3   3.0    -2.6\n2  2011  -0.4 -3.5 -2.6   0.5    -1.6\n3  2012  11.8  4.7  2.1  -0.7     4.0\n4  2013  -4.7 -4.7 -1.6   0.2    -2.6"
                    },
                    "execution_count": 34,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Selection of Features\n\ndf.columns\n",
            "execution_count": 35,
            "outputs": [
                {
                    "data": {
                        "text/plain": "Index(['Year', '1Q', '2Q', '3Q', '4Q', 'Annual'], dtype='object')"
                    },
                    "execution_count": 35,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Feature Set\n\nX = df[['Year', '1Q','2Q','3Q','4Q', 'Annual']].values \n#X=df.to_numpy()\nX[0:5]",
            "execution_count": 37,
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([[ 2.009e+03, -1.070e+01, -4.900e+00, -8.500e+00, -1.390e+01,\n        -9.500e+00],\n       [ 2.010e+03, -1.060e+01, -5.000e+00,  1.300e+00,  3.000e+00,\n        -2.600e+00],\n       [ 2.011e+03, -4.000e-01, -3.500e+00, -2.600e+00,  5.000e-01,\n        -1.600e+00],\n       [ 2.012e+03,  1.180e+01,  4.700e+00,  2.100e+00, -7.000e-01,\n         4.000e+00],\n       [ 2.013e+03, -4.700e+00, -4.700e+00, -1.600e+00,  2.000e-01,\n        -2.600e+00]])"
                    },
                    "execution_count": 37,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Labels\n\ny = df['Annual'].values\ny[0:5]",
            "execution_count": 38,
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([-9.5, -2.6, -1.6,  4. , -2.6])"
                    },
                    "execution_count": 38,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Normalize Data",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Data Standardization to give zero mean and unit variance\n\nX = preprocessing.StandardScaler().fit(X).transform(X.astype(float))\nX[0:5]",
            "execution_count": 39,
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([[-1.58113883e+00, -1.39998009e+00, -1.01572418e+00,\n        -1.83879863e+00, -2.49511529e+00, -1.97531687e+00],\n       [-1.26491106e+00, -1.38638805e+00, -1.03696556e+00,\n         2.74447556e-01,  5.84844421e-01, -5.06888365e-01],\n       [-9.48683298e-01, -6.79058793e-17, -7.18344855e-01,\n        -5.66538170e-01,  1.29229079e-01, -2.94072639e-01],\n       [-6.32455532e-01,  1.65822884e+00,  1.02344831e+00,\n         4.46957449e-01, -8.94662853e-02,  8.97695425e-01],\n       [-3.16227766e-01, -5.84457706e-01, -9.73241416e-01,\n        -3.50900804e-01,  7.45552378e-02, -5.06888365e-01]])"
                    },
                    "execution_count": 39,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Train-Split-Test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\nprint('Train set:', X_train.shape, y_train.shape)\nprint('Test set:', X_test.shape, y_test.shape)\n",
            "execution_count": 41,
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Train set: (8, 6) (8,)\nTest set: (3, 6) (3,)\n"
                }
            ]
        },
        {
            "metadata": {
                "scrolled": false
            },
            "cell_type": "code",
            "source": "# Dataset 2: Fatality Rate per 100 Million Vehicle Miles Traveled\n\ndf1=pd.read_csv('Fatality_Rate.csv',delimiter=';')\ndf1.head()",
            "execution_count": 3,
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>1Q</th>\n      <th>2Q</th>\n      <th>3Q</th>\n      <th>4Q</th>\n      <th>Annual</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2009</td>\n      <td>1.09</td>\n      <td>1.16</td>\n      <td>1.17</td>\n      <td>1.12</td>\n      <td>1.15</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2010</td>\n      <td>0.98</td>\n      <td>1.09</td>\n      <td>1.18</td>\n      <td>1.14</td>\n      <td>1.11</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2011</td>\n      <td>0.98</td>\n      <td>1.09</td>\n      <td>1.18</td>\n      <td>1.17</td>\n      <td>1.10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2012</td>\n      <td>1.08</td>\n      <td>1.12</td>\n      <td>1.21</td>\n      <td>1.16</td>\n      <td>1.14</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2013</td>\n      <td>1.04</td>\n      <td>1.07</td>\n      <td>1.17</td>\n      <td>1.15</td>\n      <td>1.10</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   Year    1Q    2Q    3Q    4Q  Annual\n0  2009  1.09  1.16  1.17  1.12    1.15\n1  2010  0.98  1.09  1.18  1.14    1.11\n2  2011  0.98  1.09  1.18  1.17    1.10\n3  2012  1.08  1.12  1.21  1.16    1.14\n4  2013  1.04  1.07  1.17  1.15    1.10"
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df1.columns",
            "execution_count": 13,
            "outputs": [
                {
                    "data": {
                        "text/plain": "Index(['Year', '1Q', '2Q', '3Q', '4Q', 'Annual'], dtype='object')"
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ]
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "# Dataset 3: Vehicle Miles Travelled Monthly Total\n\ndf2=pd.read_csv('VMT09to18.csv',delimiter=',')\n\nnew_order=[1,0,2,3]\ndf3=df2[df2.columns[new_order]]\ndf3.head()",
            "execution_count": 9,
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Month</th>\n      <th>VMT</th>\n      <th>Seasonally Adjusted VMT (2009 to present)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2009</td>\n      <td>Jan</td>\n      <td>225,529</td>\n      <td>245,487</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2009</td>\n      <td>Feb</td>\n      <td>217,643</td>\n      <td>249,041</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2009</td>\n      <td>Mar</td>\n      <td>249,741</td>\n      <td>245,286</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2009</td>\n      <td>Apr</td>\n      <td>251,374</td>\n      <td>247,503</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2009</td>\n      <td>May</td>\n      <td>258,276</td>\n      <td>246,975</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   Year Month      VMT Seasonally Adjusted VMT (2009 to present)\n0  2009   Jan  225,529                                   245,487\n1  2009   Feb  217,643                                   249,041\n2  2009   Mar  249,741                                   245,286\n3  2009   Apr  251,374                                   247,503\n4  2009   May  258,276                                   246,975"
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df3.columns",
            "execution_count": 14,
            "outputs": [
                {
                    "data": {
                        "text/plain": "Index(['Year', 'Month', 'VMT', 'Seasonally Adjusted VMT (2009 to present)'], dtype='object')"
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Algorithm selection",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Fit models",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Tune parameters",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Prediction",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Evaluation",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}