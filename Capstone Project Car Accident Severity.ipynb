{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Car Accident Severity Resulting in Fatalities #\n\n## Introduction ##\n'Since March 2020 the corona-virus pandemic a _shelter-in-place_ order has minimized vehicles on thr roadways.  Instead of the minimal vehicles on the roadways, providing a safer  enviroment and insurance claim activity [cost], the opposite has occured.  Between the National Highway Safety Admininstration (NHTSA) and Insurance Service Office (ISO), car accident severity is rising at an alarming pace.  How can this be correct!  Basic logical deduction: _Less vehicle traffic produces less traffic accidents, especially server accidents._\n\nIn today's news, one health spokeman announced that the corona-virus pandemic's United States _shelter-in-place_ strategy could last until the end of 2021!  This is a study using Machine Learning alogrithms to __predict__ 07/2020 to 06/2021 fatalities based on a prior 12 months of data.'\n\n## Business Problem ##\n'Annually, insurance companies perform a _rate-making_ process to set premium rates, also known as _insurance pricing_. A rate is the price unit of insurance for each exposure unit. Vehicle coverage as property and casualty insurance, the exposure unit is typically equal to \\\\$100 of property value, and liability is measured in \\\\$1000 units. This study is focused on liability.'\n\n'Key _rate-making_ personnel are insurance underwriters and actuaries.'\n\n'The _rate-making_ process workflow is as follows:\n> 1. Identify the car accidents with fatalities data points\n> 2. Categorize data points: car fatalities, timing and volume\n> 3. Select Machine Learning Predictive Alogritm\n> 4. Perform Parameter Tuning and Averaging\n> 5. Create 2021 rates\n\n \n\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Data Section ##\n\n### Resources ###\n\n> __NHTSA: Early Estimates of Motoer Vehicle Fatalities, 2019__\n>> - Fatalities Quarterly data with percentage of change\n>> - 10-Regional counts and percentage of change<br>\n\n> __Injury Facts NSC: Traffic Volume/Averages__\n>> - Volume of Miles Driven\n>> - Number deaths\n>> - Number of Fatal Crashes<br>\n\n> __NSC January 2019 and June 2020__\n>> - Total U.S. Motor Vehicle Deaths\n>>>  - comparisons for 2020, 2019, 2018\n>>>  - percentage change\n>>>>   - 2019 to 2020\n>>>>   - 2018 to 2020\n\nUsing supervised learning to identify data patterns in creating __2021__ fatalities predictions based on above mentioned analysis."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Methodology ##\n\nMachine Learning Pipeline: (numbered in processing order)\n> 1. preprocessing data\n> 2. selection of feature(s)\n> 3. extraction of feature(s)\n> 4. train - test - split\n> 5. algorithm selection\n> 6. fit the models\n> 7. tunr the parameters\n> 8. _prediction_\n> 9. evaluation\n\n\n\n#### Source Data ####\n'To coincide with existing __Car Accident Fatality__ findings only NSC monthly numbers are analyzed.  Data is compiled in monthly Excel spreadsheets.  Consider the spreadsheets as source data.  The source data populate *accident* Pandas dataframe. Accident dataframe contents '\n\n#### Feature Extraction ####\nComparing data from 2009 versus 2020  \n> Identify trends and/or patterns\n> Vehicle Miles Traveled (VMT)\n> Fatality Rate per 100 million VMT\n\n#### Machine Learning Model ###\n'Supervised Learning algoritms will afford using the patterns in the traffic fatalities data to make predictions. Random Forests Algorithm afford prediction, analysis and results. \n\n__Justification:__\n> Prediction for *Probabilites, Categorical Outcomes and Continous Outcomes*\n> Analysis is *Simple to Use*\n> Results are *Highly Accurate*\n\n__Note for Model Tuning Parameters strategies:__\n> Adjusting all the parameters of the Decision Tree\n> Changing the Number of Trees\n> Number of variables to select at the split\n\n## Results ##\nUse current report analysis are benchmark and provide findings for consideration to *Rate-making* process. Fatalities have a strong influence of liability cost considerations and insurer exposture. \n\n## Discussion ##\n\n## Conclusion ##"
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [],
            "source": "# Preprocessing"
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>1Q</th>\n      <th>2Q</th>\n      <th>3Q</th>\n      <th>4Q</th>\n      <th>Annual</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2009</td>\n      <td>-10.70%</td>\n      <td>-4.90%</td>\n      <td>-8.50%</td>\n      <td>-13.90%</td>\n      <td>-9.50%</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2010</td>\n      <td>-10.60%</td>\n      <td>-5.00%</td>\n      <td>1.30%</td>\n      <td>3.00%</td>\n      <td>-2.60%</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2011</td>\n      <td>-0.40%</td>\n      <td>-3.50%</td>\n      <td>-2.60%</td>\n      <td>0.50%</td>\n      <td>-1.60%</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2012</td>\n      <td>11.80%</td>\n      <td>4.70%</td>\n      <td>2.10%</td>\n      <td>-0.70%</td>\n      <td>4.00%</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2013</td>\n      <td>-4.70%</td>\n      <td>-4.70%</td>\n      <td>-1.60%</td>\n      <td>0.20%</td>\n      <td>-2.60%</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   Year       1Q      2Q      3Q       4Q  Annual\n0  2009  -10.70%  -4.90%  -8.50%  -13.90%  -9.50%\n1  2010  -10.60%  -5.00%   1.30%    3.00%  -2.60%\n2  2011   -0.40%  -3.50%  -2.60%    0.50%  -1.60%\n3  2012   11.80%   4.70%   2.10%   -0.70%   4.00%\n4  2013   -4.70%  -4.70%  -1.60%    0.20%  -2.60%"
                    },
                    "execution_count": 28,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "import numpy as np\nimport pandas as pd\n\ndf = pd.read_csv('Percentage_change.csv',delimiter=';')\ndf.head()"
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {
                "scrolled": false
            },
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>1Q</th>\n      <th>2Q</th>\n      <th>3Q</th>\n      <th>4Q</th>\n      <th>Annual</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2009</td>\n      <td>1.09</td>\n      <td>1.16</td>\n      <td>1.17</td>\n      <td>1.12</td>\n      <td>1.15</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2010</td>\n      <td>0.98</td>\n      <td>1.09</td>\n      <td>1.18</td>\n      <td>1.14</td>\n      <td>1.11</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2011</td>\n      <td>0.98</td>\n      <td>1.09</td>\n      <td>1.18</td>\n      <td>1.17</td>\n      <td>1.10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2012</td>\n      <td>1.08</td>\n      <td>1.12</td>\n      <td>1.21</td>\n      <td>1.16</td>\n      <td>1.14</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2013</td>\n      <td>1.04</td>\n      <td>1.07</td>\n      <td>1.17</td>\n      <td>1.15</td>\n      <td>1.10</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   Year    1Q    2Q    3Q    4Q  Annual\n0  2009  1.09  1.16  1.17  1.12    1.15\n1  2010  0.98  1.09  1.18  1.14    1.11\n2  2011  0.98  1.09  1.18  1.17    1.10\n3  2012  1.08  1.12  1.21  1.16    1.14\n4  2013  1.04  1.07  1.17  1.15    1.10"
                    },
                    "execution_count": 29,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df1=pd.read_csv('Fatality_Rate.csv',delimiter=';')\ndf1.head()"
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Month</th>\n      <th>Date</th>\n      <th>VMT</th>\n      <th>Seasonally Adjusted VMT (2009 to present)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Jan</td>\n      <td>Jan-09</td>\n      <td>225,529</td>\n      <td>245,487</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Feb</td>\n      <td>Feb-09</td>\n      <td>217,643</td>\n      <td>249,041</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Mar</td>\n      <td>Mar-09</td>\n      <td>249,741</td>\n      <td>245,286</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Apr</td>\n      <td>Apr-09</td>\n      <td>251,374</td>\n      <td>247,503</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>May</td>\n      <td>May-09</td>\n      <td>258,276</td>\n      <td>246,975</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "  Month    Date      VMT Seasonally Adjusted VMT (2009 to present)\n0   Jan  Jan-09  225,529                                   245,487\n1   Feb  Feb-09  217,643                                   249,041\n2   Mar  Mar-09  249,741                                   245,286\n3   Apr  Apr-09  251,374                                   247,503\n4   May  May-09  258,276                                   246,975"
                    },
                    "execution_count": 32,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df2=pd.read_csv('VMT09to18.csv',delimiter=',')\ndf2.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Selection of Features"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Extraction of Features"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Train-Split-Test"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Algorithm selection"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Fit models"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Tune parameters"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Prediction"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Evaluation"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}